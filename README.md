# [AAAI 2026] ReaSon: Reinforced Causal Search with Information Bottleneck for Video Understanding

The official implementation of ReaSon


## ğŸ“¢ News

- **[2025.11.13]** We realse codes of inference demo.
- **[2025.11.08]** ğŸ‰ğŸ‰ Our paper **"ReaSon: Reinforced Causal Search with Information Bottleneck for Video Understanding"** has been **accepted to AAAI 2026**!

## ğŸ§© To-Do List

- [ ] ğŸ“„ Release the paper (arXiv preprint & project page)  
- [ ] ğŸ’» Release full codes, including training and inference  
- [ ] ğŸš€ Release pretrained ReaSon policy  

## ğŸš€ Quick Start

<details>
<summary>ğŸ”§ Environment Setup</summary>

We provide a one-click installation script:

```bash
bash install.sh
```

Or install manually:

```bash
conda create -n reason python=3.9 -y
conda activate reason
git clone https://github.com/robin-hlt/AAAI26-ReaSon.git

# Install LLaVA-Video (optional)
git clone https://github.com/LLaVA-VL/LLaVA-NeXT
cd LLaVA-NeXT && pip install -e . && cd ..

# Install YOLO-World
git clone --recursive https://github.com/AILab-CVC/YOLO-World.git
cd YOLO-World && pip install -e . && cd ..

# Install ReaSon dependencies
pip install -r requirements_basic.txt
pip install "flash-attn==2.6.3" --no-build-isolation

# Fix mmdet/mmyolo related issues
sed -i "s/mmcv_maximum_version = '2.1.0'/mmcv_maximum_version = '2.3.0'/g" $(python -c "import importlib.util; filename=importlib.util.find_spec('mmdet').origin;print(filename)")
sed -i "s/mmcv_maximum_version = '2.1.0'/mmcv_maximum_version = '2.3.0'/g" $(python -c "import importlib.util; filename=importlib.util.find_spec('mmyolo').origin;print(filename)")
# pip install --upgrade setuptools

# Download model
mkdir pretrained && cd pretrained
mkdir YOLO-World && cd YOLO-World
wget https://huggingface.co/wondervictor/YOLO-World/resolve/main/yolo_world_v2_xl_obj365v1_goldg_cc3mlite_pretrain-5daf1395.pth && cd ../..

# Download data
mkdir -p data/coco/lvis
wget -O data/coco/lvis/lvis_v1_minival_inserted_image_name.json https://huggingface.co/GLIPModel/GLIP/resolve/main/lvis_v1_minival_inserted_image_name.json
mkdir -p data/texts
wget -O data/texts/lvis_v1_class_texts.json https://github.com/AILab-CVC/YOLO-World/raw/refs/heads/master/data/texts/lvis_v1_class_texts.json
```

</details>


<details>
<summary>ğŸ¬ Inference Demo</summary>

Run demo_reason.py to perform **reinforced causal search** and answer video questions:

```bash
python demo_reason.py \
    --video path/to/video.mp4 \
    --question "What is the person doing after opening the door?" \
    --save_dir outputs/demo
```

</details>


## ğŸ™ Acknowledgements

We sincerely thank the following open-source projects for providing essential components that contributed to our work

- [**TStar**](https://github.com/mll-lab-nu/TStar)
- [**LLaVA-Video**](https://github.com/LLaVA-VL/LLaVA-NeXT)
